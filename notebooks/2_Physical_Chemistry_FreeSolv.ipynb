{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.2"}},"nbformat_minor":2,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport torch\nimport torch.autograd as autograd\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torch.utils.data as Data\ntorch.manual_seed(8) # for reproduce\n\nimport time\nimport numpy as np\nimport gc\nimport sys\nsys.setrecursionlimit(50000)\nimport pickle\ntorch.backends.cudnn.benchmark = True\ntorch.set_default_tensor_type('torch.cuda.FloatTensor')\n# from tensorboardX import SummaryWriter\ntorch.nn.Module.dump_patches = True\nimport copy\nimport pandas as pd\n#then import my own modules\nfrom AttentiveFP import Fingerprint, Fingerprint_viz, save_smiles_dicts, get_smiles_dicts, get_smiles_array, moltosvg_highlight","metadata":{},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from rdkit import Chem\n# from rdkit.Chem import AllChem\nfrom rdkit.Chem import QED\nfrom rdkit.Chem import rdMolDescriptors, MolSurf\nfrom rdkit.Chem.Draw import SimilarityMaps\nfrom rdkit import Chem\nfrom rdkit.Chem import AllChem\nfrom rdkit.Chem import rdDepictor\nfrom rdkit.Chem.Draw import rdMolDraw2D\n%matplotlib inline\nfrom numpy.polynomial.polynomial import polyfit\nimport matplotlib.pyplot as plt\nfrom matplotlib import gridspec\nimport matplotlib.cm as cm\nimport matplotlib\nimport seaborn as sns; sns.set_style(\"darkgrid\")\nfrom IPython.display import SVG, display\nimport sascorer\nimport itertools\nfrom sklearn.metrics import r2_score\nimport scipy","metadata":{},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"random_seed = 8 # 69, 88\nstart_time = str(time.ctime()).replace(':','-').replace(' ','_')\n\nbatch_size = 200\nepochs = 200\n\np_dropout= 0.2\nfingerprint_dim = 200\n\nweight_decay = 5 # also known as l2_regularization_lambda\nlearning_rate = 2.5\noutput_units_num = 1 # for regression model\nradius = 2\nT = 2","metadata":{},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"task_name = 'hydration free energy'\ntasks = ['expt']\n\nraw_filename = \"../data/SAMPL.csv\"\nfeature_filename = raw_filename.replace('.csv','.pickle')\nfilename = raw_filename.replace('.csv','')\nprefix_filename = raw_filename.split('/')[-1].replace('.csv','')\nsmiles_tasks_df = pd.read_csv(raw_filename)\nsmilesList = smiles_tasks_df.smiles.values\nprint(\"number of all smiles: \",len(smilesList))\natom_num_dist = []\nremained_smiles = []\ncanonical_smiles_list = []\nfor smiles in smilesList:\n    try:        \n        mol = Chem.MolFromSmiles(smiles)\n        atom_num_dist.append(len(mol.GetAtoms()))\n        remained_smiles.append(smiles)\n        canonical_smiles_list.append(Chem.MolToSmiles(Chem.MolFromSmiles(smiles), isomericSmiles=True))\n    except:\n        print(smiles)\n        pass\nprint(\"number of successfully processed smiles: \", len(remained_smiles))\nsmiles_tasks_df = smiles_tasks_df[smiles_tasks_df[\"smiles\"].isin(remained_smiles)]\n# print(smiles_tasks_df)\nsmiles_tasks_df['cano_smiles'] =canonical_smiles_list\n\nplt.figure(figsize=(5, 3))\nsns.set(font_scale=1.5)\nax = sns.distplot(atom_num_dist, bins=28, kde=False)\nplt.tight_layout()\n# plt.savefig(\"atom_num_dist_\"+prefix_filename+\".png\",dpi=200)\nplt.show()\nplt.close()\n","metadata":{},"execution_count":4,"outputs":[{"name":"stdout","output_type":"stream","text":"number of all smiles:  642\n\nnumber of successfully processed smiles:  642\n"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":"<Figure size 360x216 with 1 Axes>"},"metadata":{}}]},{"cell_type":"code","source":"if os.path.isfile(feature_filename):\n    feature_dicts = pickle.load(open(feature_filename, \"rb\" ))\nelse:\n    feature_dicts = save_smiles_dicts(smilesList,filename)\n# feature_dicts = get_smiles_dicts(smilesList)\nremained_df = smiles_tasks_df[smiles_tasks_df[\"cano_smiles\"].isin(feature_dicts['smiles_to_atom_mask'].keys())]\nuncovered_df = smiles_tasks_df.drop(remained_df.index)\nprint(\"not processed items\")\nuncovered_df","metadata":{},"execution_count":5,"outputs":[{"name":"stdout","output_type":"stream","text":"N\n\nS\n\nC\n\nfeature dicts file saved as ../data/SAMPL.pickle\n\nnot processed items\n"},{"execution_count":5,"output_type":"execute_result","data":{"text/html":"<div>\n\n<style scoped>\n\n    .dataframe tbody tr th:only-of-type {\n\n        vertical-align: middle;\n\n    }\n\n\n\n    .dataframe tbody tr th {\n\n        vertical-align: top;\n\n    }\n\n\n\n    .dataframe thead th {\n\n        text-align: right;\n\n    }\n\n</style>\n\n<table border=\"1\" class=\"dataframe\">\n\n  <thead>\n\n    <tr style=\"text-align: right;\">\n\n      <th></th>\n\n      <th>iupac</th>\n\n      <th>smiles</th>\n\n      <th>expt</th>\n\n      <th>calc</th>\n\n      <th>cano_smiles</th>\n\n    </tr>\n\n  </thead>\n\n  <tbody>\n\n    <tr>\n\n      <th>61</th>\n\n      <td>ammonia</td>\n\n      <td>N</td>\n\n      <td>-4.29</td>\n\n      <td>-4.018</td>\n\n      <td>N</td>\n\n    </tr>\n\n    <tr>\n\n      <th>195</th>\n\n      <td>hydrogen sulfide</td>\n\n      <td>S</td>\n\n      <td>-0.70</td>\n\n      <td>-1.135</td>\n\n      <td>S</td>\n\n    </tr>\n\n    <tr>\n\n      <th>286</th>\n\n      <td>methane</td>\n\n      <td>C</td>\n\n      <td>2.00</td>\n\n      <td>2.446</td>\n\n      <td>C</td>\n\n    </tr>\n\n  </tbody>\n\n</table>\n\n</div>","text/plain":"                iupac smiles  expt   calc cano_smiles\n\n61            ammonia      N -4.29 -4.018           N\n\n195  hydrogen sulfide      S -0.70 -1.135           S\n\n286           methane      C  2.00  2.446           C"},"metadata":{}}]},{"cell_type":"code","source":"remained_df = remained_df.reset_index(drop=True)\ntest_df = remained_df.sample(frac=1/10, random_state=random_seed) # test set\ntraining_data = remained_df.drop(test_df.index) # training data\n\n# training data is further divided into validation set and train set\nvalid_df = training_data.sample(frac=1/9, random_state=random_seed) # validation set\ntrain_df = training_data.drop(valid_df.index) # train set\ntrain_df = train_df.reset_index(drop=True)\nvalid_df = valid_df.reset_index(drop=True)\ntest_df = test_df.reset_index(drop=True)\n\n# print(len(test_df),sorted(test_df.cano_smiles.values))\n","metadata":{},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array([canonical_smiles_list[0]],feature_dicts)\nnum_atom_features = x_atom.shape[-1]\nnum_bond_features = x_bonds.shape[-1]\nloss_function = nn.MSELoss()\nmodel = Fingerprint(radius, T, num_atom_features, num_bond_features,\n            fingerprint_dim, output_units_num, p_dropout)\nmodel.cuda()\n\n# optimizer = optim.Adam(model.parameters(), learning_rate, weight_decay=weight_decay)\noptimizer = optim.Adam(model.parameters(), 10**-learning_rate, weight_decay=10**-weight_decay)\n# optimizer = optim.SGD(model.parameters(), 10**-learning_rate, weight_decay=10**-weight_decay)\n\n# tensorboard = SummaryWriter(log_dir=\"runs/\"+start_time+\"_\"+prefix_filename+\"_\"+str(fingerprint_dim)+\"_\"+str(p_dropout))\n\nmodel_parameters = filter(lambda p: p.requires_grad, model.parameters())\nparams = sum([np.prod(p.size()) for p in model_parameters])\nprint(params)\nfor name, param in model.named_parameters():\n    if param.requires_grad:\n        print(name, param.data.shape)\n        ","metadata":{"scrolled":true},"execution_count":7,"outputs":[{"name":"stdout","output_type":"stream","text":"863604\n\natom_fc.weight torch.Size([200, 39])\n\natom_fc.bias torch.Size([200])\n\nneighbor_fc.weight torch.Size([200, 49])\n\nneighbor_fc.bias torch.Size([200])\n\nGRUCell.0.weight_ih torch.Size([600, 200])\n\nGRUCell.0.weight_hh torch.Size([600, 200])\n\nGRUCell.0.bias_ih torch.Size([600])\n\nGRUCell.0.bias_hh torch.Size([600])\n\nGRUCell.1.weight_ih torch.Size([600, 200])\n\nGRUCell.1.weight_hh torch.Size([600, 200])\n\nGRUCell.1.bias_ih torch.Size([600])\n\nGRUCell.1.bias_hh torch.Size([600])\n\nalign.0.weight torch.Size([1, 400])\n\nalign.0.bias torch.Size([1])\n\nalign.1.weight torch.Size([1, 400])\n\nalign.1.bias torch.Size([1])\n\nattend.0.weight torch.Size([200, 200])\n\nattend.0.bias torch.Size([200])\n\nattend.1.weight torch.Size([200, 200])\n\nattend.1.bias torch.Size([200])\n\nmol_GRUCell.weight_ih torch.Size([600, 200])\n\nmol_GRUCell.weight_hh torch.Size([600, 200])\n\nmol_GRUCell.bias_ih torch.Size([600])\n\nmol_GRUCell.bias_hh torch.Size([600])\n\nmol_align.weight torch.Size([1, 400])\n\nmol_align.bias torch.Size([1])\n\nmol_attend.weight torch.Size([200, 200])\n\nmol_attend.bias torch.Size([200])\n\noutput.weight torch.Size([1, 200])\n\noutput.bias torch.Size([1])\n"}]},{"cell_type":"code","source":"def train(model, dataset, optimizer, loss_function):\n    model.train()\n    np.random.seed(epoch)\n    valList = np.arange(0,dataset.shape[0])\n    #shuffle them\n    np.random.shuffle(valList)\n    batch_list = []\n    for i in range(0, dataset.shape[0], batch_size):\n        batch = valList[i:i+batch_size]\n        batch_list.append(batch)   \n    for counter, train_batch in enumerate(batch_list):\n        batch_df = dataset.loc[train_batch,:]\n        smiles_list = batch_df.cano_smiles.values\n        y_val = batch_df[tasks[0]].values\n        \n        x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array(smiles_list,feature_dicts)\n        atoms_prediction, mol_prediction = model(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask))\n        \n        model.zero_grad()\n        loss = loss_function(mol_prediction, torch.Tensor(y_val).view(-1,1))     \n        loss.backward()\n        optimizer.step()\ndef eval(model, dataset):\n    model.eval()\n    eval_MAE_list = []\n    eval_MSE_list = []\n    valList = np.arange(0,dataset.shape[0])\n    batch_list = []\n    for i in range(0, dataset.shape[0], batch_size):\n        batch = valList[i:i+batch_size]\n        batch_list.append(batch) \n    for counter, eval_batch in enumerate(batch_list):\n        batch_df = dataset.loc[eval_batch,:]\n        smiles_list = batch_df.cano_smiles.values\n#         print(batch_df)\n        y_val = batch_df[tasks[0]].values\n        \n        x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array(smiles_list,feature_dicts)\n        atoms_prediction, mol_prediction = model(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask))\n        MAE = F.l1_loss(mol_prediction, torch.Tensor(y_val).view(-1,1), reduction='none')        \n        MSE = F.mse_loss(mol_prediction, torch.Tensor(y_val).view(-1,1), reduction='none')\n#         print(x_mask[:2],atoms_prediction.shape, mol_prediction,MSE)\n        \n        eval_MAE_list.extend(MAE.data.squeeze().cpu().numpy())\n        eval_MSE_list.extend(MSE.data.squeeze().cpu().numpy())\n    return np.array(eval_MAE_list).mean(), np.array(eval_MSE_list).mean()\n","metadata":{},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"best_param ={}\nbest_param[\"train_epoch\"] = 0\nbest_param[\"valid_epoch\"] = 0\nbest_param[\"train_MSE\"] = 9e8\nbest_param[\"valid_MSE\"] = 9e8\n\nfor epoch in range(800):\n    train_MAE, train_MSE = eval(model, train_df)\n    valid_MAE, valid_MSE = eval(model, valid_df)\n#     tensorboard.add_scalars('MAE',{'train_MAE':valid_MAE, 'test_MAE':valid_MSE}, epoch)\n#     tensorboard.add_scalars('MSE',{'train_MSE':valid_MAE, 'test_MSE':valid_MSE}, epoch)\n    if train_MSE < best_param[\"train_MSE\"]:\n        best_param[\"train_epoch\"] = epoch\n        best_param[\"train_MSE\"] = train_MSE\n    if valid_MSE < best_param[\"valid_MSE\"]:\n        best_param[\"valid_epoch\"] = epoch\n        best_param[\"valid_MSE\"] = valid_MSE\n        if valid_MSE < 0.8:\n             torch.save(model, 'saved_models/model_'+prefix_filename+'_'+start_time+'_'+str(epoch)+'.pt')\n    if (epoch - best_param[\"train_epoch\"] >8) and (epoch - best_param[\"valid_epoch\"] >18):        \n        break\n    print(epoch, np.sqrt(train_MSE), np.sqrt(valid_MSE))\n    \n    train(model, train_df, optimizer, loss_function)\n","metadata":{"scrolled":true},"execution_count":9,"outputs":[{"name":"stdout","output_type":"stream","text":"0 5.4889116 4.6295986\n\n1 3.4889457 3.3459234\n\n2 3.4868627 3.1838691\n\n3 3.4330826 3.3401072\n\n4 3.2898693 2.9853556\n\n5 3.1701777 2.8678808\n\n6 3.0564284 2.7971344\n\n7 2.8336735 2.4655533\n\n8 2.4719226 2.2088935\n\n9 2.287127 2.0497832\n\n10 2.2077966 2.018041\n\n11 2.0893774 1.9935333\n\n12 1.8485503 1.7601727\n\n13 1.6490041 1.6649685\n\n14 1.5777755 1.6284981\n\n15 1.4293296 1.4772525\n\n16 1.327753 1.3336158\n\n17 1.3639141 1.382638\n\n18 1.2715518 1.1776\n\n19 1.2102355 1.2026784\n\n20 1.1350868 1.0462834\n\n21 1.1109627 1.0017744\n\n22 1.0982748 1.0629967\n\n23 1.0786741 0.9782093\n\n24 1.096344 1.0988955\n\n25 1.0427724 1.0293592\n\n26 1.0058757 0.9393151\n\n27 1.0150261 0.9684016\n\n28 0.96819484 0.9374981\n\n29 0.9588202 0.9714065\n\n30 0.92903477 0.92668974\n\n31 0.9290548 0.9499346\n\n32 0.91146487 0.9308738\n\n33 0.9080392 0.92374986\n\n34 0.9284361 0.9211718\n\n35 0.9704258 1.0355911\n\n36 0.9314613 1.0441777\n\n37 0.8423892 0.92023414\n\n38 0.8611789 0.9110354\n\n39 0.9563538 0.9655793\n\n40 1.0293821 1.0470486\n\n41 0.8695605 0.8421852\n\n42 0.8241618 0.85899824\n\n43 0.807163 0.88604337\n\n44 0.78734684 0.8758821\n\n45 0.77236617 0.8579956\n\n46 0.761375 0.85923713\n\n47 0.74925935 0.8446477\n\n48 0.7704745 0.85803455\n\n49 0.75718606 0.8478531\n\n50 0.7618507 0.8283638\n\n51 0.7311341 0.8767507\n\n52 0.72508276 0.8174579\n\n53 0.7666273 0.8285475\n\n54 0.8072457 0.83288664\n\n55 0.74398875 0.7979583\n\n56 0.7658374 0.83128434\n\n57 0.7120842 0.7803842\n\n58 0.7058376 0.8464185\n\n59 0.7727066 0.8626394\n\n60 0.670557 0.8188596\n\n61 0.67851454 0.8160039\n\n62 0.6804413 0.83660614\n\n63 0.6425536 0.7713331\n\n64 0.6680422 0.76976025\n\n65 0.6332084 0.75911367\n\n66 0.6672612 0.81196374\n\n67 0.61793685 0.75099236\n\n68 0.61166614 0.7735851\n\n69 0.6006518 0.76635134\n\n70 0.5702351 0.7492754\n\n71 0.5856702 0.7685989\n\n72 0.549227 0.743797\n\n73 0.60967207 0.8287278\n\n74 0.55009484 0.72344553\n\n75 0.74403876 0.75586736\n\n76 0.83668405 0.97652036\n\n77 0.65979815 0.77188313\n\n78 0.5686105 0.700448\n\n79 0.5515963 0.70117146\n\n80 0.5435944 0.7224567\n\n81 0.53352475 0.725009\n\n82 0.5161656 0.7234237\n\n83 0.5108444 0.7332786\n\n84 0.4883259 0.75793654\n\n85 0.48869282 0.7402075\n\n86 0.46796247 0.73234636\n\n87 0.46145216 0.74260414\n\n88 0.46249267 0.7340735\n\n89 0.4420388 0.7214831\n\n90 0.44192 0.7258047\n\n91 0.4356227 0.7776863\n\n92 0.43360326 0.7575617\n\n93 0.41419137 0.7346601\n\n94 0.42798027 0.7177743\n\n95 0.43671784 0.7721355\n\n96 0.4159135 0.7522777\n\n97 0.40940207 0.7453004\n\n98 0.39631823 0.76806223\n\n99 0.39013296 0.7266327\n\n100 0.4054874 0.6979912\n\n101 0.39175105 0.756163\n\n102 0.38885757 0.8098543\n\n103 0.43884537 0.7610465\n\n104 0.38389546 0.7078637\n\n105 0.44026086 0.73777074\n\n106 0.4615209 0.7593217\n\n107 0.40068346 0.7525127\n\n108 0.4156446 0.6985681\n\n109 0.50117207 0.7622611\n\n110 0.36574626 0.78943306\n\n111 0.3822775 0.7711778\n\n112 0.47448546 0.76422364\n\n113 0.46211165 0.8638066\n\n114 0.46102524 0.75599647\n\n115 0.4543082 0.8107612\n\n116 0.43157881 0.7293751\n\n117 0.41874844 0.76567096\n\n118 0.39226112 0.76337135\n"}]},{"cell_type":"code","source":"# evaluate model\nbest_model = torch.load('saved_models/model_'+prefix_filename+'_'+start_time+'_'+str(best_param[\"valid_epoch\"])+'.pt')     \n\nbest_model_dict = best_model.state_dict()\nbest_model_wts = copy.deepcopy(best_model_dict)\n\nmodel.load_state_dict(best_model_wts)\n(best_model.align[0].weight == model.align[0].weight).all()\ntest_MAE, test_MSE = eval(model, test_df)\nprint(\"best epoch:\",best_param[\"valid_epoch\"],\"\\n\",\"test RMSE:\",np.sqrt(test_MSE))","metadata":{},"execution_count":10,"outputs":[{"name":"stdout","output_type":"stream","text":"best epoch: 100 \n\n test RMSE: 0.7729235\n"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}